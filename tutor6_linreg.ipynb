{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <i>Supervised Learning</i> \n",
    "\n",
    "# Tutorial Linear Regresion\n",
    "\n",
    "As a refresher, we will start by learning how to implement linear regression. The main idea is to get familiar with objective functions, computing their gradients and optimizing the objectives over a set of parameters. These basic tools will form the basis for more sophisticated algorithms later. Readers that want additional details may refer to the <a href=\"http://cs229.stanford.edu/notes/cs229-notes1.pdf\">Stanford CS229 Notes</a> on Supervised Learning for more.\n",
    "\n",
    "To perform supervised learning, we must decide how we’re going to represent functions/hypotheses $h$ in a computer. As an initial choice, let’s say we decide to approximate $y$ as a linear function of $x$:\n",
    "\n",
    "$$h_\\theta(x) = \\theta_0+\\theta_1x_1+\\theta_2x_2$$\n",
    "\n",
    "Here, the $\\theta_i$ are the parameters (also called weights) parameterizing the space of linear functions mapping from\n",
    "$X$ to $Y$. To simplify our notation, we also introduce the convention of letting $x_0 = 1$ (this is the intercept term).\n",
    "\n",
    "\n",
    "\n",
    "Our goal is to find a function $y=h(x)$ so that we have $y^{(i)} \\approx h(x^{(i)})$ for each training example. To find a function $h(x)$ where $y^{(i)} \\approx h(x^{(i)})$ we must first decide how to represent the function $h(x)$. To start out we will use linear functions:\n",
    "\n",
    "$$h_\\theta(x) = \\sum_j^n \\theta_j x_j = \\theta^\\top x$$\n",
    "\n",
    "Where on the right-hand side above we are viewing $\\theta$ and $x$ both as vectors, and here $n$ is the number of input variables/features (not counting $x_0$). Here, $h_\\theta(x)$ represents a large family of functions parametrized by the choice of $\\theta$. (We call this space of functions a “hypothesis class”.) With this representation for $h$, our task is to find a choice of $\\theta$ so that $h(x^{(i)})$ is as close as possible to $y(i)$. In particular, we will search for a choice of $\\theta$ that minimizes:\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{2} \\sum_i^m \\left( h_\\theta(x^{(i)}) - y^{(i)} \\right)^2 = \\frac{1}{2} \\sum_i^m \\left( \\theta^\\top x^{(i)} - y^{(i)} \\right)^2\n",
    "$$\n",
    "\n",
    "The index $m$ is number data (instance) and this function is the <b>\"cost function\"</b> for our problem, which measures how much error is incurred in predicting $y^{(i)}$ for a particular choice of $\\theta$. This may also be called a \"loss\", \"penalty\" or \"objective\" function.\n",
    "\n",
    "There are many algorithms for minimizing functions like this one and we will describe some very effective ones that are easy to implement. Let’s consider the <b>Gradient Descent</b> algorithm, which starts with some initial $\\theta$, and repeatedly performs the update:\n",
    "$$\n",
    "\\theta_j:=\\theta_j - \\alpha \\frac{\\partial }{\\partial \\theta_j} J(\\theta)\n",
    "$$\n",
    "(This update is simultaneously performed for all values of $j = 0, . . . , n$.). Here, $\\alpha$ is called the learning rate. This is a very natural algorithm that repeatedly takes a step in the direction of steepest decrease of $J$.\n",
    "Differentiating the cost function $J(θ)$ as given above with respect to a particular parameter $\\theta_j$ gives us:\n",
    "$$\n",
    "\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\sum_i x^{(i)}_j \\left(h_\\theta(x^{(i)}) - y^{(i)}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Linear Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano as th\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from theano import tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate xdata input\n",
    "xdata = np.linspace(-1, 1, 101)\n",
    "\n",
    "# likes: y = mx + c  \n",
    "# Generate ydata output\n",
    "ydata = 5 * xdata + np.random.randn(*xdata.shape) * 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEKCAYAAAASByJ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f17ca72b210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show/Plot generated data ydata by xdata\n",
    "plt.plot(xdata, ydata, '.')\n",
    "plt.ylabel('y data')\n",
    "plt.xlabel('x data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize theano variables\n",
    "\n",
    "# learning rate\n",
    "alph = 0.01\n",
    "\n",
    "# X, Y input as scalar\n",
    "x = T.dscalar()\n",
    "y = T.dscalar()\n",
    "\n",
    "# w shared var as float \n",
    "# w is a gradient in cartesian quadrant base on above plot\n",
    "w = th.shared(0., name='w')\n",
    "\n",
    "# Prediction function as a linear function, y = m*x, w as m (slope), y predicted\n",
    "f_pred = x * w\n",
    "\n",
    "# square error function\n",
    "f_err = T.sqr(f_pred - y)\n",
    "\n",
    "# Cost function as a mean of all square (quadrat) error data / J(theta)\n",
    "f_cost = T.mean(f_err)\n",
    "\n",
    "# Compute Gradient of cost w (theta)\n",
    "gw = T.grad(cost=f_cost, wrt=w)\n",
    "\n",
    "f_upd = [[w, w - (alph * gw)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the training function\n",
    "\n",
    "f_train = th.function(inputs=[x, y], outputs=[f_pred, f_err], updates=f_upd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w before train: 0.000000 \n"
     ]
    }
   ],
   "source": [
    "# W before train\n",
    "print('w before train: %f ' % w.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, '4.69', '4.87', '0.0312')\n"
     ]
    }
   ],
   "source": [
    "# Training Process\n",
    "epoch = 100\n",
    "for i in range(epoch):\n",
    "    for x_, y_ in zip(xdata, ydata):\n",
    "        pred, err = f_train(x_, y_)\n",
    "\n",
    "print(i, '%.2f'%y_ , '%.2f'%pred, '%.4f'%err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w after train: 4.865888 \n"
     ]
    }
   ],
   "source": [
    "# W after train, W is something around 5 as a mention in ydata equation.\n",
    "print('w after train: %f ' % w.get_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: for xtest = 0.500000 then ypred = 2.432944 \n"
     ]
    }
   ],
   "source": [
    "# Predict y from xtest using W value have got from training\n",
    "xtest = 0.5\n",
    "ypred = xtest * w\n",
    "print(\"Predicted: for xtest = %f then ypred = %f \" % (xtest, float(ypred.eval())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
